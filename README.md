# Awesome-Deep-Research

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

[NEWS.2024/11/10] **The latest version of our [paper](https://arxiv.org/abs/2404.18861v3) (v3) is now available! This update includes numerous high-quality papers on visual Mamba.**


ðŸ“¢**NOTE:** If you have any questions, please don't hesitate to contact us at any of the following emails: [fengpeilin@pjlab.org.cn](mailto:fengpeilin@pjlab.org.cn)

Mamba, a novel state space model, has gained recognition across diverse domains for its exceptional performance and efficient computational complexity. By addressing the limitations inherent in traditional visual foundation architectures, Mamba emerges as a promising contender poised to catalyze advancements in the field of computer vision.

:star: This repository hosts a curated collection of literature associated with Mamba models in computer vision. Feel free to star and fork. For further details, refer to the following paper:

**[Visual Mamba: A Survey and New Outlooks](https://arxiv.org/abs/2404.18861v2)**<br/>
Rui Xu, Shu Yang, Yihui Wang, Yu Cai, Bo Du, [Hao Chen](https://cse.hkust.edu.hk/~jhc/)<br/>
[SMART Lab](https://hkustsmartlab.github.io/), The Hong Kong University of Science and Technology<br/>
<br/>



<!-- ## Contents
- [Awesome-Deep-Research](#awesome-deep-research)
  - [Contents](#contents)
  - [Mamba](#mamba)
  - [Related Survey](#related-survey)
  - [Visual Mamba Backbone Networks](#visual-mamba-backbone-networks)
  - [Vision Application](#vision-application)
    - [Image](#image)
      - [Natural Image](#natural-image) -->

## Mamba
| Date      | Paper | Figure    | Link | Code         |
| :-------- | :---- | :-------- | :--- | :----------- |
| Arxiv 23.12.01 (COLM 2024) | Mamba: Linear-Time Sequence Modeling with Selective State Spaces | ![image](https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models/assets/57466105/9b1d1ebf-213b-4aa8-8cc9-852a62c997bf) ![image](https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models/assets/57466105/25b4bb74-5592-4953-8667-cb40ecc72914) |[Link](https://arxiv.org/pdf/2312.00752)|[Code](https://github.com/state-spaces/mamba)|

## Related Survey

| Date      | Paper | Link |
| :-------- | :---- | :-------- |
<!-- | Arxiv 24.04.15|State Space Model for New-Generation Network Alternative to Transformers: A Survey | [Link](https://arxiv.org/pdf/2404.09516) | -->


## Visual Mamba Backbone Networks
<img width="600" alt="image" src="https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models/assets/57466105/4843bead-14cd-4aa6-aecf-af9411defc49">


[Detailed Performance Comparison](SOTA_Results.md)


| Date      | Paper | Figure    | Link | Code         |
| :-------- | :---- | :-------- | :--- | :----------- |
<!-- | Arxiv 24.01.17 (ICML 2024)| Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model|<img width="684" alt="image" src="https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models/assets/74030174/6d32c807-3d2f-457e-8927-fa4bbe595064"> |[Link](https://arxiv.org/abs/2401.09417)|[Code](https://github.com/hustvl/Vim)| -->





## Vision Application
### Image

#### Natural Image

| Date      | Paper | Figure    | Link | Code         | Task |
| :-------- | :---- | :-------- | :--- | :----------- | :--- |




