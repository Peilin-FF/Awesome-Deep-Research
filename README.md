# Awesome-Deep-Research

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

<!-- [NEWS.2025/03/12] **I have preliminarily completed the arrangement of the paper, and you are welcome to correct and participate.** -->

AI-powered research assistant has attracted great attention in the community. It is a key step for mankind to move towards general artificial intelligence (AGI)! This repo is dedicated to organizing the current technical routes and papers of Deep Research, hoping to help research in this field.

üì¢**NOTE:** This is a popular work recently, so the codes of many papers have not been open sourced. If you know that some work has been updated, please leave a message in the issues and I will update it in time!

üì¢**NOTE:** If you have any questions, please don't hesitate to contact us at any of the following emails: [fengpeilin@pjlab.org.cn](mailto:fengpeilin@pjlab.org.cn)

:star: This repository hosts a curated collection of literature associated with Deep Research(AI-powered research assistant). Please share a ‚≠ê if this project does help!

## Contents
- [Awesome-Deep-Research](#awesome-deep-research)
  - [Contents](#contents)
  - [Related Surveys](#related-surveys)
  - [Awesome Frameworks](#awesome-frameworks)
  - [Awesome Publications](#awesome-publications)
    - [Foundation Research](#foundation-research)
    - [Coorperation Strategy Research](#coorperation-strategy-research)
    - [Awesome AI-powered Researchers](#awesome-ai-powered-researchers)
    - [Evaluation](#evaluation)
      - [Evaluation Methods](#evaluation-methods)
      - [Benchmark](#benchmark)
    - [Rethinking](#rethinking)

## Related Surveys

| Date      | Repository | Description | Link |
| :-------- | :------- | :-------- | :--- |
| 24.05 | awesome-llm-apps | A curated collection of awesome LLM apps built with RAG and AI agents. | [Link](https://github.com/Shubhamsaboo/awesome-llm-apps)[![GitHub stars](https://img.shields.io/github/stars/Shubhamsaboo/awesome-llm-apps?style=social)](https://github.com/Shubhamsaboo/awesome-llm-apps) |


## Awesome Frameworks

These widely used open source frameworks can effectively help the development of Deep Research.

| Date      | Repository | Description | Link |
| :-------- | :------- | :-------- | :--- |
| 22.11 | langchain | A framework for developing applications powered by large language models (LLMs). | [Link](https://github.com/langchain-ai/langchain)[![GitHub stars](https://img.shields.io/github/stars/langchain-ai/langchain)](https://github.com/langchain-ai/langchain) |
| 22.11 | llama_index | LlamaIndex (GPT Index) is a data framework for your LLM application | [Link](https://github.com/run-llama/llama_index)[![GitHub stars](https://img.shields.io/github/stars/run-llama/llama_index)](https://github.com/run-llama/llama_index) |
| 23.03 | AutoGPT | AutoGPT is a powerful platform that allows you to create, deploy, and manage continuous AI agents that automate complex workflows. | [Link](https://github.com/Significant-Gravitas/AutoGPT)[![GitHub stars](https://img.shields.io/github/stars/Significant-Gravitas/AutoGPT)](https://github.com/Significant-Gravitas/AutoGPT) |
| 23.04 | AgentGPT | AgentGPT allows you to configure and deploy Autonomous AI agents | [Link](https://github.com/reworkd/AgentGPT)[![GitHub stars](https://img.shields.io/github/stars/reworkd/AgentGPT)](https://github.com/reworkd/AgentGPT) |
| 23.04 | JARVIS | The mission of JARVIS is to explore artificial general intelligence (AGI) and deliver cutting-edge research to the whole community. | [Link](https://github.com/microsoft/JARVIS)[![GitHub stars](https://img.shields.io/github/stars/microsoft/JARVIS)](https://github.com/microsoft/JARVIS) |
| 23.04 | camel | CAMEL is an open-source community dedicated to finding the scaling laws of agents.  | [Link](https://github.com/camel-ai/camel)[![GitHub stars](https://img.shields.io/github/stars/camel-ai/camel)](https://github.com/camel-ai/camel) |
| 23.06 | AutoChain | Building generative agents based on objectives expressed in natural language | [Link](https://github.com/Forethought-Technologies/AutoChain)[![GitHub stars](https://img.shields.io/github/stars/Forethought-Technologies/AutoChain)](https://github.com/Forethought-Technologies/AutoChain) |
| 23.06 | ollama | A framework that simplifies the development of large-scale machine learning models | [Link](https://github.com/ollama/ollama)[![GitHub stars](https://img.shields.io/github/stars/ollama/ollama)](https://github.com/ollama/ollama) |
| 23.06 | vllm | A fast and easy-to-use library for LLM inference and serving | [Link](https://github.com/vllm-project/vllm)[![GitHub stars](https://img.shields.io/github/stars/vllm-project/vllm)](https://github.com/vllm-project/vllm) |
| 23.06 | web-llm | WebLLM is a high-performance in-browser LLM inference engine that brings language model inference directly onto web browsers with hardware acceleration. | [Link](https://github.com/mlc-ai/web-llm)[![GitHub stars](https://img.shields.io/github/stars/mlc-ai/web-llm)](https://github.com/mlc-ai/web-llm) |
| 23.08 | AutoGen | AutoGen is a framework for creating multi-agent AI applications that can act autonomously or work alongside humans | [Link](https://github.com/microsoft/autogen)[![GitHub stars](https://img.shields.io/github/stars/microsoft/autogen)](https://github.com/microsoft/autogen) |
| 23.08 | lightllm | A Python-based LLM (Large Language Model) inference and serving framework | [Link](https://github.com/ModelTC/lightllm)[![GitHub stars](https://img.shields.io/github/stars/ModelTC/lightllm)](https://github.com/ModelTC/lightllm) |


## Awesome Publications
### Foundation Research
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2017  (SNAPL 2017) | Natural Language is a Programming Language: Applying Natural Language Processing to Software Development | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/natural-language-is-a-programming-language-applying-natural-language-processing-to-software-development.png) | [Link](https://drops.dagstuhl.de/storage/00lipics/lipics-vol071-snapl2017/LIPIcs.SNAPL.2017.4/LIPIcs.SNAPL.2017.4.pdf) |  |
| 2022.03 ÔºàNeurIPS 2022) | Training language models to follow instructions with human feedback | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/training-language-models-to-follow-instructions-with-human-feedback.png) | [Link](https://arxiv.org/pdf/2203.02155) |  |
| 2022.01  (NeurIPS 2022) | Chain-of-Thought Prompting Elicits Reasoning in Large Language Models | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/chain-of-thought-prompting-elicits-reasoning-in-large-language-models.png) | [Link](https://arxiv.org/pdf/2201.11903) | |
| 2022.03 | Self-Consistency Improves Chain of Thought Reasoning in Language Models  (ICLR 2023)| ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/self-consistency-improves-chain-of-thought-reasoning-in-language-models.png) | [Link](https://arxiv.org/pdf/2203.11171) | |
| 2023.08 | AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/AutoGen.png) | [Link](https://arxiv.org/pdf/2308.08155) | [Code](https://github.com/microsoft/autogen)[![GitHub stars](https://img.shields.io/github/stars/microsoft/autogen)](https://github.com/microsoft/autogen) |
| 2023.08 | MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/MetaGPT.png) | [Link](https://arxiv.org/pdf/2308.00352) | [Code](https://github.com/geekan/MetaGPT)[![GitHub stars](https://img.shields.io/github/stars/geekan/MetaGPT)](https://github.com/geekan/MetaGPT) |
| 2023.10 | MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/MetaAgents.png) | [Link](https://arxiv.org/pdf/2310.06500) | [Code](https://github.com/microsoft/autogen)[![GitHub stars](https://img.shields.io/github/stars/microsoft/autogen)](https://github.com/microsoft/autogen) |
| 2023.10 | OpenAgents: An Open Platform for Language Agents in the Wild | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/OpenAgents.png) | [Link](https://arxiv.org/pdf/2310.10634) | [Code](https://github.com/xlang-ai/OpenAgents)[![GitHub stars](https://img.shields.io/github/stars/xlang-ai/OpenAgents)](https://github.com/xlang-ai/OpenAgents) |
| 2025.03 | Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs | ![image](https://github.com/Peilin-FF/Awesome-Deep-Research/blob/main/assets/Foundation_Research/Mask-DPO.png) | [Link](https://arxiv.org/pdf/2503.02846) | [Code](https://github.com/open-compass/ANAH)[![GitHub stars](https://img.shields.io/github/stars/open-compass/ANAH)](https://github.com/open-compass/ANAH) |


### Coorperation Strategy Research
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2023.03 | CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society | ![image](placeholder) | [Link](https://arxiv.org/pdf/2303.17760) | [Code](placeholder) |
| 2023.07 | ChatDev: Communicative Agents for Software Development | ![image](placeholder) | [Link](https://aclanthology.org/2024.acl-long.810.pdf) | [Code](placeholder) |
| 2023.08 | ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate | ![image](placeholder) | [Link](https://arxiv.org/pdf/2308.07201) | [Code](placeholder) |
| 2023.08 | AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors | ![image](placeholder) | [Link](https://arxiv.org/pdf/2308.10848) | [Code](placeholder) |
| 2024.06 | Generative AI Voting: Fair Collective Choice is Resilient to LLM Biases and Inconsistencies | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.11871) | [Code](placeholder) |
| 2024.12 | LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.06229) | [Code](placeholder) |
| 2025.01 | Debate Helps Weak-to-Strong Generalization | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.13124) | [Code](placeholder) |


### Awesome AI-powered Researchers
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2021.02 | Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks | ![image](placeholder) | [Link](https://arxiv.org/pdf/2102.12592) | [Code](placeholder) |
| 2021.04 | Accelerating science with human versus alien artificial intelligences | ![image](placeholder) | [Link](https://arxiv.org/pdf/2104.05188) | [Code](placeholder) |
| 2022.02 | AI Research Associate for Early-Stage Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/pdf/2202.03199) | [Code](placeholder) |
| 2022.08 | Effidit: Your AI Writing Assistant | ![image](placeholder) | [Link](https://arxiv.org/pdf/2208.01815) | [Code](placeholder) |
| 2022.10 | Artificial Intelligence for Scientific Research: Authentic Research Education Framework | ![image](placeholder) | [Link](https://arxiv.org/pdf/2210.08966) | [Code](placeholder) |
| 2022.11 | AI Assistants: A Framework for Semi-Automated Data Wrangling | ![image](placeholder) | [Link](https://arxiv.org/pdf/2211.00192) | [Code](placeholder) |
| 2023.02 | CARE: Collaborative AI-Assisted Reading Environment | ![image](placeholder) | [Link](https://arxiv.org/pdf/2302.12611) | [Code](placeholder) |
| 2023.04 | Beyond Summarization: Designing AI Support for Real-World Expository Writing Tasks | ![image](placeholder) | [Link](https://arxiv.org/pdf/2304.02623) | [Code](placeholder) |
| 2023.04 | ChemCrow: Augmenting large-language models with chemistry tools | ![image](placeholder) | [Link](https://arxiv.org/pdf/2304.05376) | [Code](placeholder) |
| 2023.06 | Accelerating science with human-aware artificial intelligence | ![image](placeholder) | [Link](https://arxiv.org/pdf/2306.01495) | [Code](placeholder) |
| 2023.06 | Interactive Editing for Text Summarization | ![image](placeholder) | [Link](https://arxiv.org/pdf/2306.03067) | [Code](placeholder) |
| 2023.06 | AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn | ![image](placeholder) | [Link](https://arxiv.org/pdf/2306.08640) | [Code](placeholder) |
| 2023.07 | ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs | ![image](placeholder) | [Link](https://arxiv.org/pdf/2307.16789) | [Code](placeholder) |
| 2023.10 | GeoLLM: Extracting Geospatial Knowledge from Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2310.06213) | [Code](placeholder) |
| 2023.11 | LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2311.05437) | [Code](placeholder) |
| 2023.11 | AcademicGPT: Empowering Academic Research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2311.12315) | [Code](placeholder) |
| 2023.12 | Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.06153) | [Code](placeholder) |
| 2023.12 | Agent-based Learning of Materials Datasets from Scientific Literature | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.11690) | [Code](placeholder) |
| 2023.12 | GEAR-Up: Generative AI and External Knowledge-based Retrieval Upgrading Scholarly Article Searches for Systematic Reviews | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.09948) | [Code](placeholder) |
| 2023.12 | ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (Local) Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.14607) | [Code](placeholder) |
| 2024.01 | LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward | ![image](placeholder) | [Link](https://arxiv.org/pdf/2401.03374) | [Code](placeholder) |
| 2024.01 | Weaver: Foundation Models for Creative Writing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2401.17268) | [Code](placeholder) |
| 2024.02 | Prompt-Time Symbolic Knowledge Capture with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.00414) | [Code](placeholder) |
| 2024.02 | DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.17453) | [Code](placeholder) |
| 2024.02 | An Autonomous Large Language Model Agent for Chemical Literature Data Mining | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.12993) | [Code](placeholder) |
| 2024.02 | Multi-line AI-assisted Code Authoring | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.04141) | [Code](placeholder) |
| 2024.02 | Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.18582) | [Code](placeholder) |
| 2024.03 | AutoDev: Automated AI-Driven Development | ![image](placeholder) | [Link](https://arxiv.org/pdf/2403.08299) | [Code](placeholder) |
| 2024.03 | ChatDBG: An AI-Powered Debugging Assistant | ![image](placeholder) | [Link](https://arxiv.org/pdf/2403.16354) | [Code](placeholder) |
| 2024.03 | LLMs as Academic Reading Companions: Extending HCI Through Synthetic Personae | ![image](placeholder) | [Link](https://arxiv.org/pdf/2403.19506) | [Code](placeholder) |
| 2024.04 | DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.00439) | [Code](placeholder) |
| 2024.04 | Empowering Biomedical Discovery with AI Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.02831) | [Code](placeholder) |
| 2024.04 | ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.07738) | [Code](placeholder) |
| 2024.04 | Exploring Human-AI Collaboration in Agile: Customised LLM Meeting Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.14871) | [Code](placeholder) |
| 2024.05 | A System for Quantifying Data Science Workflows with Fine-Grained Procedural Logging and a Pilot Study | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.17845) | [Code](placeholder) |
| 2024.05 | A FAIR and Free Prompt-based Research Assistant | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.14601) | [Code](placeholder) |
| 2024.05 | Automated Focused Feedback Generation for Scientific Writing Assistance | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.20477) | [Code](placeholder) |
| 2024.06 | BugBlitz-AI: An Intelligent QA Assistant | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.04356) | [Code](placeholder) |
| 2024.04 | SARA: Smart AI Reading Assistant for Reading Comprehension | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.06906) | [Code](placeholder) |
| 2024.06 | The Use of AI-Robotic Systems for Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.17835) | [Code](placeholder) |
| 2024.07 | Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.02651) | [Code](placeholder) |
| 2024.07 | SeqMate: A Novel Large Language Model Pipeline for Automating RNA Sequencing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.03381) | [Code](placeholder) |
| 2024.07 | AI-Assisted SQL Authoring at Industry Scale | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.13280) | [Code](placeholder) |
| 2024.08 | The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/pdf/2408.06292) | [Code](placeholder) |
| 2024.08 | Genesis: Towards the Automation of Systems Biology Research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2408.10689) | [Code](placeholder) |
| 2024.09 | Collective Predictive Coding as Model of Science: Formalizing Scientific Activities Towards Generative Science | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.00102) | [Code](placeholder) |
| 2024.09 | SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.05556) | [Code](placeholder) |
| 2024.09 | PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.00092) | [Code](placeholder) |
| 2024.09 | Steward: Natural Language Web Automation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.15441) | [Code](placeholder) |
| 2024.09 | NoTeeline: Supporting Real-Time, Personalized Notetaking with LLM-Enhanced Micronotes | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.16493) | [Code](placeholder) |
| 2024.10 | Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.09403) | [Code](placeholder) |
| 2024.10 | A Multi-LLM Orchestration Engine for Personalized, Context-Rich Assistance | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.10039) | [Code](placeholder) |
| 2024.10 | Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.10136) | [Code](placeholder) |
| 2024.10 | Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.11009) | [Code](placeholder) |
| 2024.10 | AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.17469) | [Code](placeholder) |
| 2024.10 | Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.24119) | [Code](placeholder) |
| 2024.10 | AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.21480) | [Code](placeholder) |
| 2024.11 | Semantic Navigation for AI-assisted Ideation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.03575) | [Code](placeholder) |
| 2024.11 | MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.08063) | [Code](placeholder) |
| 2024.11 | AIGS: Generating Science from AI-Powered Automated Falsification | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.11910) | [Code](placeholder) |
| 2024.11 | CycleResearcher: Improving Automated Research via Automated Review | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.00816) | [Code](placeholder) |
| 2024.12 | A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.15404) | [Code](placeholder) |
| 2024.12 | MetaScientist: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial Design | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.16270) | [Code](placeholder) |
| 2024.12 | Multi-Agent System for Cosmological Parameter Analysis | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.00431) | [Code](placeholder) |
| 2024.12 | TapeAgents: a Holistic Framework for Agent Development and Optimization | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.08445) | [Code](placeholder) |
| 2024.12 | LLMs can Realize Combinatorial Creativity: Generating Creative Ideas via LLMs for Scientific Research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.14141) | [Code](placeholder) |
| 2024.12 | EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.18100) | [Code](placeholder) |
| 2024.12 | VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.18161) | [Code](placeholder) |
| 2024.12 | Automated Code Review In Practice | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.18531) | [Code](placeholder) |
| 2025.01 | Agent Laboratory: Using LLM Agents as Research Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.04227) | [Code](placeholder) |
| 2025.01 | Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.03916) | [Code](placeholder) |
| 2025.01 | Knowledge Retrieval Based on Generative AI | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.04635) | [Code](placeholder) |
| 2025.01 | Automating Care by Self-maintainability for Full Laboratory Automation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.05789) | [Code](placeholder) |
| 2025.02 | AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.05957) | [Code](placeholder) |
| 2025.02 | AIDE: AI-Driven Exploration in the Space of Code | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.13138) | [Code](placeholder) |
| 2025.02 | Towards an AI co-scientist | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.18864) | [Code](placeholder) |
| 2025.02 | ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.00989) | [Code](placeholder) |
| 2025.02 | Knowledge Synthesis of Photosynthesis Research Using a Large Language Model | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.01059) | [Code](placeholder) |
| 2025.02 | Accelerating Scientific Research Through a Multi-LLM Framework | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.07960) | [Code](placeholder) |
| 2025.02 | Automated Capability Discovery via Model Self-Exploration | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.07577) | [Code](placeholder) |
| 2025.02 | CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.10884) | [Code](placeholder) |
| 2025.02 | From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.15237) | [Code](placeholder) |
| 2025.02 | AI-Instruments: Embodying Prompts as Instruments to pdftract & Reflect Graphical Interface Commands as General-Purpose Tools | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.18736) | [Code](placeholder) |
| 2025.03 | Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty | ![image](placeholder) | [Link](https://arxiv.org/pdf/2503.01508) | [Code](placeholder) |



### Evaluation
#### Evaluation Methods
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2021.10 | Learning to Assist Agents by Observing Them | ![image](placeholder) | [Link](https://arxiv.org/pdf/2110.01311) | [Code](placeholder) |
| 2021.10 | Explaining Reward Functions to Humans for Better Human-Robot Collaboration | ![image](placeholder) | [Link](https://arxiv.org/pdf/2110.04192) | [Code](placeholder) |
| 2023.04 | VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping | ![image](placeholder) | [Link](https://arxiv.org/pdf/2304.07810) | [Code](placeholder) |
| 2023.04 | Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT | ![image](placeholder) | [Link](https://arxiv.org/pdf/2304.10778) | [Code](placeholder) |
| 2024.06 | A Knowledge-Component-Based Methodology for Evaluating AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.05603) | [Code](placeholder) |
| 2024.06 | AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.19256) | [Code](placeholder) |
| 2024.09 | Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and Debugging Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.19922) | [Code](placeholder) |
| 2024.10 | Aligning AI-driven discovery with human intuition | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.07397) | [Code](placeholder) |
| 2024.10 | Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.14879) | [Code](placeholder) |
| 2024.10 | GigaCheck: Detecting LLM-generated Content | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.23728) | [Code](placeholder) |
| 2024.12 | CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.11261) | [Code](placeholder) |
| 2025.01 | Fine-Grained Appropriate Reliance: Human-AI Collaboration with a Multi-Step Transparent Decision Workflow for Complex Task Decomposition | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.10909) | [Code](placeholder) |
| 2025.01 | Self-Explanation in Social AI Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.13945) | [Code](placeholder) |
| 2025.02 | Bridging Logic Programming and Deep Learning for Explainability through ILASP | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.09227) | [Code](placeholder) |
| 2025.02 | EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.20309) | [Code](placeholder) |
| 2025.02 | Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.21266) | [Code](placeholder) |
| 2025.03 | The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars | ![image](placeholder) | [Link](https://arxiv.org/pdf/2503.05820) | [Code](placeholder) |
| 2025.03 | Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty | ![image](placeholder) | [Link](https://arxiv.org/pdf/2503.01508) | [Code](placeholder) |


#### Benchmark
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2022.09 | Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering | ![image](placeholder) | [Link](https://arxiv.org/pdf/2209.09513) | [Code](placeholder) |
| 2023.08 | BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2308.05960) | [Code](placeholder) |
| 2023.07 | MegaWika: Millions of reports and their sources across 50 diverse languages | ![image](placeholder) | [Link](https://arxiv.org/pdf/2307.07049) | [Code](placeholder) |
| 2023.08 | LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles | ![image](placeholder) | [Link](https://arxiv.org/pdf/2308.10855) | [Code](placeholder) |
| 2023.10 | OceanGPT: A Large Language Model for Ocean Science Tasks | ![image](placeholder) | [Link](https://arxiv.org/pdf/2310.02031) | [Code](placeholder) |
| 2023.11 | GAIA: a benchmark for General AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2311.12983) | [Code](placeholder) |
| 2024.02 | LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model | ![image](placeholder) | [Link](https://arxiv.org/pdf/2402.02544) | [Code](placeholder) |
| 2024.05 | "Turing Tests" For An AI Scientist | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.13352) | [Code](placeholder) |
| 2024.06 | MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.06357) | [Code](placeholder) |
| 2024.07 | SciCode: A Research Coding Benchmark Curated by Scientists | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.13168) | [Code](placeholder) |
| 2024.07 | MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.04903) | [Code](placeholder) |
| 2024.08 | GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI | ![image](placeholder) | [Link](https://arxiv.org/pdf/2408.03361) | [Code](placeholder) |
| 2024.09 | DSBench: How Far Are Data Science Agents to Becoming Data Science Experts? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.07703) | [Code](placeholder) |
| 2024.09 | ChemDFM-X: Towards Large Multimodal Model for Chemistry | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.13194) | [Code](placeholder) |
| 2024.09 | CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.13903) | [Code](placeholder) |
| 2024.09 | UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.19898) | [Code](placeholder) |
| 2024.10 | CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.01999) | [Code](placeholder) |
| 2024.10 | AutoPenBench: Benchmarking Generative Agents for Penetration Testing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.03225) | [Code](placeholder) |
| 2024.10 | AAAR-1.0: Assessing AI's Potential to Assist Research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.22394) | [Code](placeholder) |
| 2024.11 | INQUIRE: A Natural World Text-to-Image Retrieval Benchmark | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.02537) | [Code](placeholder) |
| 2024.11 | SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.00172) | [Code](placeholder) |
| 2024.11 | RedCode: Risky Code Execution and Generation Benchmark for Code Agents | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.07781) | [Code](placeholder) |
| 2024.11 | LLM4DS: Evaluating Large Language Models for Data Science Code Generation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.11908) | [Code](placeholder) |
| 2024.12 | How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.18573) | [Code](placeholder) |
| 2025.02 | Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.15224) | [Code](placeholder) |
| 2025.02 | Learning to Coordinate with Experts | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.09583) | [Code](placeholder) |
| 2025.02 | UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.00334) | [Code](placeholder) |
| 2025.02 | Minerva: A Programmable Memory Test Benchmark for Language Models | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.03358) | [Code](placeholder) |
| 2025.02 | Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.09906) | [Code](placeholder) |
| 2025.02 | Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.15815) | [Code](placeholder) |
### Rethinking
| Date | Paper | Figure | Link | Code |
| :--- | :---- | :--------- | :--- | :--- |
| 2021.01 | How Much Automation Does a Data Scientist Want? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2101.03970) | [Code](placeholder) |
| 2021.03 | Toward Building Science Discovery Machines | ![image](placeholder) | [Link](https://arxiv.org/pdf/2103.15551) | [Code](placeholder) |
| 2021.11 | Automated scholarly paper review: Concepts, technologies, and challenges | ![image](placeholder) | [Link](https://arxiv.org/pdf/2111.07533) | [Code](placeholder) |
| 2023.01 | How Data Scientists Review the Scholarly Literature | ![image](placeholder) | [Link](https://arxiv.org/pdf/2301.03774) | [Code](placeholder) |
| 2023.03 | Practices and Challenges of Using GitHub Copilot: An Empirical Study | ![image](placeholder) | [Link](https://arxiv.org/pdf/2303.08733) | [Code](placeholder) |
| 2023.03 | A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges | ![image](placeholder) | [Link](https://arxiv.org/pdf/2303.17125) | [Code](placeholder) |
| 2023.05 | Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems | ![image](placeholder) | [Link](https://arxiv.org/pdf/2305.02251) | [Code](placeholder) |
| 2023.05 | Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond | ![image](placeholder) | [Link](https://arxiv.org/pdf/2305.15299) | [Code](placeholder) |
| 2023.06 | The Future of AI-Assisted Writing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2306.16641) | [Code](placeholder) |
| 2023.07 | What Should Data Science Education Do with Large Language Models? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2307.02792) | [Code](placeholder) |
| 2023.07 | The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence | ![image](placeholder) | [Link](https://arxiv.org/pdf/2307.07522) | [Code](placeholder) |
| 2023.07 | AI empowering research: 10 ways how science can benefit from AI | ![image](placeholder) | [Link](https://arxiv.org/pdf/2307.10265) | [Code](placeholder) |
| 2023.10 | AI for Mathematics: A Cognitive Science Perspective | ![image](placeholder) | [Link](https://arxiv.org/pdf/2310.13021) | [Code](placeholder) |
| 2023.10 | Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities | ![image](placeholder) | [Link](https://arxiv.org/pdf/2310.16164) | [Code](placeholder) |
| 2023.11 | Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance | ![image](placeholder) | [Link](https://arxiv.org/pdf/2311.03311) | [Code](placeholder) |
| 2023.12 | Drivers and Barriers of AI Adoption and Use in Scientific Research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.09843) | [Code](placeholder) |
| 2023.12 | Generative AI in Writing Research Papers: A New Type of Algorithmic Bias and Uncertainty in Scholarly Work | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.10057) | [Code](placeholder) |
| 2023.12 | Exploring the intersection of Generative AI and Software Development | ![image](placeholder) | [Link](https://arxiv.org/pdf/2312.14262) | [Code](placeholder) |
| 2024.01 | Can AI Assistants Know What They Don't Know? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2401.13275) | [Code](placeholder) |
| 2024.03 | "It is there, and you need it, so why do you not use it?" Achieving better adoption of AI systems by domain experts, in the case study of natural science research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2403.16895) | [Code](placeholder) |
| 2024.03 | Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals | ![image](placeholder) | [Link](https://arxiv.org/pdf/2403.14592) | [Code](placeholder) |
| 2024.04 | Deceptive Patterns of Intelligent and Interactive Writing Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.09375) | [Code](placeholder) |
| 2024.04 | How far are AI-powered programming assistants from meeting developers' needs? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.12000) | [Code](placeholder) |
| 2024.04 | Augmenting the Author: Exploring the Potential of AI Collaboration in Academic Writing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2404.16071) | [Code](placeholder) |
| 2024.05 | From Complexity to Clarity: How AI Enhances Perceptions of Scientists and the Public's Understanding of Science | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.00706) | [Code](placeholder) |
| 2024.05 | Transforming Software Development with Generative AI: Empirical Insights on Collaboration and Workflow | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.01543) | [Code](placeholder) |
| 2024.05 | What Can Natural Language Processing Do for Peer Review? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.06563) | [Code](placeholder) |
| 2024.05 | Using ChatGPT for Thematic Analysis | ![image](placeholder) | [Link](https://arxiv.org/pdf/2405.08828) | [Code](placeholder) |
| 2024.06 | Using AI-Based Coding Assistants in Practice: State of Affairs, Perceptions, and Ways Forward | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.07765) | [Code](placeholder) |
| 2024.06 | Explain the Black Box for the Sake of Science: the Scientific Method in the Era of Generative Artificial Intelligence | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.10557) | [Code](placeholder) |
| 2024.06 | Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2406.11375) | [Code](placeholder) |
| 2024.07 | Large Language Models as Misleading Assistants in Conversation | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.11789) | [Code](placeholder) |
| 2024.07 | The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.12015) | [Code](placeholder) |
| 2024.07 | Exploring the Evidence-Based Beliefs and Behaviors of LLM-Based Programming Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2407.13900) | [Code](placeholder) |
| 2024.08 | Generative AI Tools in Academic Research: Applications and Implications for Qualitative and Quantitative Research Methodologies | ![image](placeholder) | [Link](https://arxiv.org/pdf/2408.06872) | [Code](placeholder) |
| 2024.09 | Emerging Reliance Behaviors in Human-AI Text Generation: Hallucinations, Data Quality Assessment, and Cognitive Forcing Functions | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.08937) | [Code](placeholder) |
| 2024.09 | Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.11192) | [Code](placeholder) |
| 2024.09 | Mining Causality: AI-Assisted Search for Instrumental Variables | ![image](placeholder) | [Link](https://arxiv.org/pdf/2409.14202) | [Code](placeholder) |
| 2024.10 | The why, what, and how of AI-based coding in scientific research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.02156) | [Code](placeholder) |
| 2024.10 | How Does the Disclosure of AI Assistance Affect the Perceptions of Writing? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.04545) | [Code](placeholder) |
| 2024.10 | Need Help? Designing Proactive AI Assistants for Programming | ![image](placeholder) | [Link](https://arxiv.org/pdf/2410.04596) | [Code](placeholder) |
| 2024.11 | Disrupting Test Development with AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.02328) | [Code](placeholder) |
| 2024.11 | AI-Empowered Human Research Integrating Brain Science and Social Sciences Insights | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.12761) | [Code](placeholder) |
| 2024.11 | Probing the limitations of multimodal language models for chemistry and materials research | ![image](placeholder) | [Link](https://arxiv.org/pdf/2411.16955) | [Code](placeholder) |
| 2024.12 | The impact of AI on engineering design procedures for dynamical systems | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.12230) | [Code](placeholder) |
| 2024.12 | Hints Help Finding and Fixing Bugs Differently in Python and Text-based Program Representations | ![image](placeholder) | [Link](https://arxiv.org/pdf/2412.12471) | [Code](placeholder) |
| 2025.01 | Experience with GitHub Copilot for Developer Productivity at Zoominfo | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.13282) | [Code](placeholder) |
| 2025.01 | Towards Decoding Developer Cognition in the Age of AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.02684) | [Code](placeholder) |
| 2025.01 | "It makes you think": Provocations Help Restore Critical Thinking to AI-Assisted Knowledge Work | ![image](placeholder) | [Link](https://arxiv.org/pdf/2501.17247) | [Code](placeholder) |
| 2025.02 | Evaluating Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial Research Intelligence' (ARI)? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.14297) | [Code](placeholder) |
| 2025.02 | Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.15657) | [Code](placeholder) |
| 2025.02 | Performance Evaluation of Large Language Models in Statistical Programming | ![image](placeholder) | [Link](https://arxiv.org/pdf/2502.13117) | [Code](placeholder) |
| 2025.03 | Position: AI agents should be regulated based on autonomous action sequences | ![image](placeholder) | [Link](https://arxiv.org/pdf/2503.04750) | [Code](placeholder) |
| 2025.03 | Unlocking the Potential of AI Researchers in Scientific Discovery: What Is Missing? | ![image](placeholder) | [Link](https://arxiv.org/pdf/2503.05822) | [Code](placeholder) |




















