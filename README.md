# Awesome-Deep-Research

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

<!-- [NEWS.2025/03/12] **I have preliminarily completed the arrangement of the paper, and you are welcome to correct and participate.** -->

AI-powered research assistant has attracted great attention in the community. It is a key step for mankind to move towards general artificial intelligence (AGI)! This repo is dedicated to organizing the current technical routes and papers of Deep Research, hoping to help research in this field.

üì¢**NOTE:** This is a popular work recently, so the codes of many papers have not been open sourced. If you know that some work has been updated, please leave a message in the issues and I will update it in time!

üì¢**NOTE:** If you have any questions, please don't hesitate to contact us at any of the following emails: [fengpeilin@pjlab.org.cn](mailto:fengpeilin@pjlab.org.cn)

:star: This repository hosts a curated collection of literature associated with Deep Research(AI-powered research assistant). Please share a ‚≠ê if this project does help!

<!-- ## Contents
- [Awesome-Deep-Research](#awesome-deep-research)
  - [Contents](#contents)
  - [Mamba](#mamba)
  - [Related Survey](#related-survey)
  - [Visual Mamba Backbone Networks](#visual-mamba-backbone-networks)
  - [Vision Application](#vision-application)
    - [Image](#image)
      - [Natural Image](#natural-image) -->

## Related Works

| Date      | Repository | Description | Link |
| :-------- | :------- | :-------- | :--- |
| 24.05 | awesome-llm-apps | A curated collection of awesome LLM apps built with RAG and AI agents. | [Link](https://github.com/Shubhamsaboo/awesome-llm-apps)[![GitHub stars](https://img.shields.io/github/stars/Shubhamsaboo/awesome-llm-apps?style=social)](https://github.com/Shubhamsaboo/awesome-llm-apps) |


## Awesome Frameworks

These widely used open source frameworks can effectively help the development of Deep Research.

| Date      | Repository | Description | Link |
| :-------- | :------- | :-------- | :--- |
| 22.11 | langchain | A framework for developing applications powered by large language models (LLMs). | [Link](https://github.com/langchain-ai/langchain)[![GitHub stars](https://img.shields.io/github/stars/langchain-ai/langchain)](https://github.com/langchain-ai/langchain) |
| 22.11 | llama_index | LlamaIndex (GPT Index) is a data framework for your LLM application | [Link](https://github.com/run-llama/llama_index)[![GitHub stars](https://img.shields.io/github/stars/run-llama/llama_index)](https://github.com/run-llama/llama_index) |
| 23.03 | AutoGPT | AutoGPT is a powerful platform that allows you to create, deploy, and manage continuous AI agents that automate complex workflows. | [Link](https://github.com/Significant-Gravitas/AutoGPT)[![GitHub stars](https://img.shields.io/github/stars/Significant-Gravitas/AutoGPT)](https://github.com/Significant-Gravitas/AutoGPT) |
| 23.04 | AgentGPT | AgentGPT allows you to configure and deploy Autonomous AI agents | [Link](https://github.com/reworkd/AgentGPT)[![GitHub stars](https://img.shields.io/github/stars/reworkd/AgentGPT)](https://github.com/reworkd/AgentGPT) |
| 23.04 | JARVIS | The mission of JARVIS is to explore artificial general intelligence (AGI) and deliver cutting-edge research to the whole community. | [Link](https://github.com/microsoft/JARVIS)[![GitHub stars](https://img.shields.io/github/stars/microsoft/JARVIS)](https://github.com/microsoft/JARVIS) |
| 23.04 | camel | CAMEL is an open-source community dedicated to finding the scaling laws of agents.  | [Link](https://github.com/camel-ai/camel)[![GitHub stars](https://img.shields.io/github/stars/camel-ai/camel)](https://github.com/camel-ai/camel) |
| 23.06 | AutoChain | Building generative agents based on objectives expressed in natural language | [Link](https://github.com/Forethought-Technologies/AutoChain)[![GitHub stars](https://img.shields.io/github/stars/Forethought-Technologies/AutoChain)](https://github.com/Forethought-Technologies/AutoChain) |
| 23.06 | ollama | A framework that simplifies the development of large-scale machine learning models | [Link](https://github.com/ollama/ollama)[![GitHub stars](https://img.shields.io/github/stars/ollama/ollama)](https://github.com/ollama/ollama) |
| 23.06 | vllm | A fast and easy-to-use library for LLM inference and serving | [Link](https://github.com/vllm-project/vllm)[![GitHub stars](https://img.shields.io/github/stars/vllm-project/vllm)](https://github.com/vllm-project/vllm) |
| 23.06 | web-llm | WebLLM is a high-performance in-browser LLM inference engine that brings language model inference directly onto web browsers with hardware acceleration. | [Link](https://github.com/mlc-ai/web-llm)[![GitHub stars](https://img.shields.io/github/stars/mlc-ai/web-llm)](https://github.com/mlc-ai/web-llm) |
| 23.08 | AutoGen | AutoGen is a framework for creating multi-agent AI applications that can act autonomously or work alongside humans | [Link](https://github.com/microsoft/autogen)[![GitHub stars](https://img.shields.io/github/stars/microsoft/autogen)](https://github.com/microsoft/autogen) |
| 23.08 | lightllm | A Python-based LLM (Large Language Model) inference and serving framework | [Link](https://github.com/ModelTC/lightllm)[![GitHub stars](https://img.shields.io/github/stars/ModelTC/lightllm)](https://github.com/ModelTC/lightllm) |


## Awesome Publications
### Foundation Research
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :--- |
| 2017 | Natural Language is a Programming Language: Applying Natural Language Processing to Software Development | ![image](placeholder) | [Link](https://drops.dagstuhl.de/storage/00lipics/lipics-vol071-snapl2017/LIPIcs.SNAPL.2017.4/LIPIcs.SNAPL.2017.4.pdf) | [Code](placeholder) | Natural Language Processing, Software Development, Bug Detection, Code Generation, Mathematical Techniques. |
| 2022.03 | Training language models to follow instructions with human feedback | ![image](placeholder) | [Link](https://arxiv.org/abs/2203.02155) | [Code](placeholder) | language models, human feedback, fine-tuning, alignment, user intent |
| 2022.01 | Chain-of-Thought Prompting Elicits Reasoning in Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2201.11903) | [Code](placeholder) | Chain-of-Thought Prompting, Large Language Models, Complex Reasoning, Chain of Thought Demonstrations, Arithmetic, Commonsense, Symbolic Reasoning Tasks, Empirical Gains, GSM8K Benchmark, Math Word Problems, Finetuned GPT-3, Verifier. |
| 2022.03 | Self-Consistency Improves Chain of Thought Reasoning in Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2203.11171) | [Code](placeholder) | Chain-of-thought prompting, self-consistency, large language models, reasoning tasks, benchmarks. |
| 2023.08 | AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.08155) | [Code](placeholder) | AutoGen, LLM applications, multi-agent conversation, customizable agents, flexible conversation patterns |
| 2023.08 | MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.00352) | [Code](placeholder) | MetaGPT, Multi-Agent Collaborative Framework, Large Language Models (LLMs), Standardized Operating Procedures (SOPs), Collaborative Software Engineering Benchmarks |
| 2023.10 | MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.06500) | [Code](placeholder) | Large Language Models, Collaborative Generative Agents, Task-oriented Coordination, Social Simulations, Human-like Reasoning Abilities |
| 2023.10 | OpenAgents: An Open Platform for Language Agents in the Wild | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.10634) | [Code](placeholder) | Language agents, Large language models (LLMs), OpenAgents, Application-level designs, Real-world evaluations |
| 2025.03 | Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.02846) | [Code](placeholder) | Large Language Models, Hallucinations, Direct Preference Optimization, Factuality Alignment, Generalization Property |


### Coorperation Strategy Research
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :--- |
| 2023.03 | CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society | ![image](placeholder) | [Link](https://arxiv.org/abs/2303.17760) | [Code](placeholder) | "Communicative Agents", "Large Language Model", "Autonomous Cooperation", "Role-playing", "Instruction-following Cooperation" |
| 2023.07 | ChatDev: Communicative Agents for Software Development | ![image](placeholder) | [Link](https://aclanthology.org/2024.acl-long.810.pdf) | [Code](placeholder) | Large Language Models (LLMs), Multi-Agent Debate Framework, Text Evaluation, Natural Language Generation (NLG), ChatEval |
| 2023.08 | ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.07201) | [Code](placeholder) | ChatEval, Large Language Models (LLMs), Multi-Agent Debate, Software Development, Linguistic Communication |
| 2023.08 | AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.10848) | [Code](placeholder) | Multi-Agent, Collaboration, Emergent Behaviors, Large Language Models, Social Behaviors |
| 2024.06 | Generative AI Voting: Fair Collective Choice is Resilient to LLM Biases and Inconsistencies | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.11871) | [Code](placeholder) | Generative AI, Voting, Fair Collective Choice, LLM Biases, Proportional Representation |
| 2024.12 | LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.06229) | [Code](placeholder) | Large Language Models (LLMs), Genetic Algorithms (GA), Adversarial Search (AS), AI-powered debate platform, adaptive arguments |
| 2025.01 | Debate Helps Weak-to-Strong Generalization | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.13124) | [Code](placeholder) | "Debate", "Weak-to-Strong Generalization", "Alignment", "Supervision", "Superhuman Models" |




### Evaluation
#### Evaluation Methods
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :------- |
| 2021.10 | Learning to Assist Agents by Observing Them | ![image](placeholder) | [Link](https://arxiv.org/abs/2110.01311) | [Code](placeholder) | AI agent, reinforcement learning, offline data, assisting policy, gridworld scenarios. |
| 2021.10 | Explaining Reward Functions to Humans for Better Human-Robot Collaboration | ![image](placeholder) | [Link](https://arxiv.org/abs/2110.04192) | [Code](placeholder) | Explainable AI, Reward Functions, Human-Robot Collaboration, Value Alignment, Reward Explanation Techniques |
| 2023.04 | VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping | ![image](placeholder) | [Link](https://arxiv.org/abs/2304.07810) | [Code](placeholder) | VISAR, AI-enabled writing assistant, argumentative writing, visual programming, rapid draft prototyping. |
| 2023.04 | Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT | ![image](placeholder) | [Link](https://arxiv.org/abs/2304.10778) | [Code](placeholder) | AI-assisted code generation, GitHub Copilot, Amazon CodeWhisperer, ChatGPT, code quality metrics |
| 2024.06 | A Knowledge-Component-Based Methodology for Evaluating AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.05603) | [Code](placeholder) | AI Assistants, Knowledge-Component-Based Methodology, Evaluating, GPT-4, CS1 Programming Assignments |
| 2024.06 | AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.19256) | [Code](placeholder) | AI Data Readiness, Quantitative Assessment, Data Quality, Machine Learning Pipeline, FAIR Principles. |
| 2024.09 | Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and Debugging Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.19922) | [Code](placeholder) | AI-driven tools, software development, large language models (LLMs), code generation, debugging assistants |
| 2024.10 | Aligning AI-driven discovery with human intuition | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.07397) | [Code](placeholder) | AI-driven discovery, human intuition, state variables, scientific modeling, human-AI collaboration. |
| 2024.10 | Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.14879) | [Code](placeholder) | Multi-modal Personal Tracking Data, Visualization, Human-In-The-Loop LLM Agents, Context-Driven Sensemaking, Ubiquitous Computing Studies |
| 2024.10 | GigaCheck: Detecting LLM-generated Content | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.23728) | [Code](placeholder) | GigaCheck, LLM-generated content, text detection, Human-Machine collaborative texts, DETR-like detection model |
| 2024.12 | CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.11261) | [Code](placeholder) | CATER, machine translation, quality evaluation, large language models, reference-independent metrics |
| 2025.01 | Fine-Grained Appropriate Reliance: Human-AI Collaboration with a Multi-Step Transparent Decision Workflow for Complex Task Decomposition | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.10909) | [Code](placeholder) | Human-AI Collaboration, Multi-Step Transparent Decision Workflow, Appropriate Reliance, Complex Task Decomposition, Composite Fact-Checking Tasks. |
| 2025.01 | Self-Explanation in Social AI Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.13945) | [Code](placeholder) | Social AI, Self-Explanation, Transparency, Trust, Chain of Thought, ChatGPT, Self-Model, Online Learning, AI Social Assistant, Community Behavior. |
| 2025.02 | Bridging Logic Programming and Deep Learning for Explainability through ILASP | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.09227) | [Code](placeholder) | Deep Learning, Logic Programming, Explainable AI, ILASP, XASP |
| 2025.02 | EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.20309) | [Code](placeholder) | AI, Large Language Models, Scientific Research, Evaluation Methodology, EAIRA |
| 2025.02 | Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.21266) | [Code](placeholder) | Machine Learning, INFN Cloud, Kubernetes, GPU-powered data analysis, Virtual Kubelets. |
| 2025.03 | The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.05820) | [Code](placeholder) | AI, peer feedback, research writing skills, CGScholar platform, Kazakhstani scholars |
| 2025.03 | Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.01508) | [Code](placeholder) | Artificial General Intelligence (AGI), novelty assessment, Relative Neighbor Density (RND), domain-agnostic algorithm, scientific discovery. |


#### Benchmark
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :------- |
| 2022.09 | Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering | ![image](placeholder) | [Link](https://arxiv.org/abs/2209.09513) | [Code](placeholder) | Multimodal Reasoning, Chain of Thought (CoT), Science Question Answering, Language Models, Interpretability |
| 2023.08 | BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.05960) | [Code](placeholder) | Large Language Models (LLMs), Autonomous Agents, Benchmarking, Orchestrating, Multi-step Reasoning |
| 2023.07 | MegaWika: Millions of reports and their sources across 50 diverse languages | ![image](placeholder) | [Link](https://arxiv.org/abs/2307.07049) | [Code](placeholder) | MegaWika, collaborative AI, report generation, multilingual, cross-lingual question answering. |
| 2023.08 | LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles | ![image](placeholder) | [Link](https://arxiv.org/abs/2308.10855) | [Code](placeholder) | LLMs, Lateral Thinking, LatEval, Interactive Evaluation, Benchmarking |
| 2023.10 | OceanGPT: A Large Language Model for Ocean Science Tasks | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.02031) | [Code](placeholder) | OceanGPT, Large Language Model, Ocean Science, OceanBench, Embodied Intelligence |
| 2023.11 | GAIA: a benchmark for General AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2311.12983) | [Code](placeholder) | General AI Assistants, benchmark, reasoning, multi-modality handling, tool-use proficiency |
| 2024.02 | LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.02544) | [Code](placeholder) | Large Language Models, Multimodal Large Language Models, Remote Sensing, Volunteered Geographic Information, Image Understanding |
| 2024.05 | "Turing Tests" For An AI Scientist | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.13352) | [Code](placeholder) | AI Scientist, Turing Test, Scientific Discovery, Benchmark Tests, Autonomous Research |
| 2024.06 | MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.06357) | [Code](placeholder) | AI-Assisted Scientific Workflows, MASSW Dataset, Multi-Aspect Summarization, Large Language Models, Scientific Innovation |
| 2024.07 | SciCode: A Research Coding Benchmark Curated by Scientists | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.13168) | [Code](placeholder) | Language Models, SciCode, Scientific Research Problems, Coding Benchmark, AI Evaluation |
| 2024.07 | MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.04903) | [Code](placeholder) | Scientific figure interpretation, Large Vision Language Models, graduate-level expertise, multimodal scientific understanding, benchmark dataset. |
| 2024.08 | GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI | ![image](placeholder) | [Link](https://arxiv.org/abs/2408.03361) | [Code](placeholder) | Vision-Language Models, GMAI-MMBench, Medical AI Benchmark, Multimodal Evaluation, General Medical AI |
| 2024.09 | DSBench: How Far Are Data Science Agents to Becoming Data Science Experts? | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.07703) | [Code](placeholder) | Large Language Models, Data Science Benchmarks, Data Science Agents, Realistic Tasks, Performance Evaluation |
| 2024.09 | ChemDFM-X: Towards Large Multimodal Model for Chemistry | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.13194) | [Code](placeholder) | AI tools, Chemistry, Multimodal Model, Chemical General Intelligence, Instruction-tuning dataset |
| 2024.09 | CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.13903) | [Code](placeholder) | AI Assistants, Contextual Integrity, Synthetic Data, Privacy Challenges, Benchmarking. |
| 2024.09 | UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.19898) | [Code](placeholder) | UniSumEval, summarization evaluation, language models, fine-grained, multi-dimensional annotations |
| 2024.10 | CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.01999) | [Code](placeholder) | CodeMMLU, CodeLLMs, code understanding, benchmark, software development |
| 2024.10 | AutoPenBench: Benchmarking Generative Agents for Penetration Testing | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.03225) | [Code](placeholder) | Generative AI agents, Penetration Testing, Benchmarking, Large Language Models, Cybersecurity Tasks |
| 2024.10 | AAAR-1.0: Assessing AI's Potential to Assist Research | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.22394) | [Code](placeholder) | AI Systems, Large Language Models (LLMs), Research Tasks, Benchmark Dataset, Expertise-Intensive Tasks |
| 2024.11 | INQUIRE: A Natural World Text-to-Image Retrieval Benchmark | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.02537) | [Code](placeholder) | INQUIRE, text-to-image retrieval, multimodal vision-language models, expert-level queries, ecological challenges |
| 2024.11 | SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.00172) | [Code](placeholder) | SeafloorAI, Vision-Language Dataset, Seafloor Geological Survey, Sonar Imagery Analysis, Machine Learning Models |
| 2024.11 | RedCode: Risky Code Execution and Generation Benchmark for Code Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.07781) | [Code](placeholder) | Code Agents, Safety Concerns, Risky Code Execution, Code Generation, Benchmark Evaluation |
| 2024.11 | LLM4DS: Evaluating Large Language Models for Data Science Code Generation | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.11908) | [Code](placeholder) | Large Language Models, Data Science, Code Generation, Empirical Assessment, Task Performance |
| 2024.12 | How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.18573) | [Code](placeholder) | Code Generation, LLMs, Benchmark, Application Domains, MultiCodeBench |
| 2025.02 | Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.15224) | [Code](placeholder) | Large Language Models, Scientific Discovery, Auto-Bench, Causal Graph Discovery, Machine Intelligence |
| 2025.02 | Learning to Coordinate with Experts | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.09583) | [Code](placeholder) | AI agents, expert assistance, Learning to Yield and Request Control (YRC), YRC-Bench, coordination problem. |
| 2025.02 | UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.00334) | [Code](placeholder) | Large language models, Physics reasoning, Undergraduate physics, Benchmark, MARJ pipeline |
| 2025.02 | Minerva: A Programmable Memory Test Benchmark for Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.03358) | [Code](placeholder) | LLM-based AI assistants, memory test benchmark, programmable memory, capability tests, interpretable assessment. |
| 2025.02 | Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.09906) | [Code](placeholder) | Multimodal Conversational Generative AI, Visual Insect Understanding, Insect-LLaVA, Multimodal Insect Dataset, Insect Foundation Model |
| 2025.02 | Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.15815) | [Code](placeholder) | AI, Theoretical Physics, Benchmark, Problem Solving, Research Capabilities |

### Awesome AI-powered Researchers
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :------- |
| 2021.02 | Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks | ![image](placeholder) | [Link](https://arxiv.org/abs/2102.12592) | [Code](placeholder) | Computational Notebooks, Data Science, Documentation Generation, Human-Centered AI, Machine Learning Code Documentation |
| 2021.04 | Accelerating science with human versus alien artificial intelligences | ![image](placeholder) | [Link](https://arxiv.org/abs/2104.05188) | [Code](placeholder) | Artificial Intelligence, Human Expertise, Scientific Discovery, Prediction Engines, Collective Advance |
| 2022.02 | AI Research Associate for Early-Stage Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/abs/2202.03199) | [Code](placeholder) | Artificial Intelligence, Scientific Discovery, Physics-Based Modeling, Hypothesis Search, Tensor-Based Computation Graphs |
| 2022.08 | Effidit: Your AI Writing Assistant | ![image](placeholder) | [Link](https://arxiv.org/abs/2208.01815) | [Code](placeholder) | Effidit, AI Writing Assistant, Text Completion, Error Checking, Text Polishing |
| 2022.10 | Artificial Intelligence for Scientific Research: Authentic Research Education Framework | ![image](placeholder) | [Link](https://arxiv.org/abs/2210.08966) | [Code](placeholder) | Artificial Intelligence, Scientific Research, Authentic Research Education, Framework, Machine Learning |
| 2022.11 | AI Assistants: A Framework for Semi-Automated Data Wrangling | ![image](placeholder) | [Link](https://arxiv.org/abs/2211.00192) | [Code](placeholder) | AI Assistants, Data Wrangling, Semi-Automated, Data Engineering, Interactive Tools |
| 2023.02 | CARE: Collaborative AI-Assisted Reading Environment | ![image](placeholder) | [Link](https://arxiv.org/abs/2302.12611) | [Code](placeholder) | AI-assisted reading, inline commentary, CARE platform, NLP assistance, scholarly peer review. |
| 2023.04 | Beyond Summarization: Designing AI Support for Real-World Expository Writing Tasks | ![image](placeholder) | [Link](https://arxiv.org/abs/2304.02623) | [Code](placeholder) | AI-assisted writing, expository writing, large language models, real-world writing tasks, AI support design. |
| 2023.04 | ChemCrow: Augmenting large-language models with chemistry tools | ![image](placeholder) | [Link](https://arxiv.org/abs/2304.05376) | [Code](placeholder) | Large-language models, Computational chemistry, Organic synthesis, Drug discovery, Materials design. |
| 2023.06 | Accelerating science with human-aware artificial intelligence | ![image](placeholder) | [Link](https://arxiv.org/abs/2306.01495) | [Code](placeholder) | Artificial Intelligence, Human Expertise, Scientific Discoveries, Prediction Models, Accelerating Science |
| 2023.06 | Interactive Editing for Text Summarization | ![image](placeholder) | [Link](https://arxiv.org/abs/2306.03067) | [Code](placeholder) | Text Summarization, Neural Summarization Models, Interactive Editing, Draft Summaries, Collaborative Experience |
| 2023.06 | AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn | ![image](placeholder) | [Link](https://arxiv.org/abs/2306.08640) | [Code](placeholder) | Large Language Models, Multi-modal AI Assistant, Plan, Execute, Inspect, Learn, Visual-based tasks, Reasoning paths, Flexible inputs, Intermediate results. |
| 2023.07 | ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs | ![image](placeholder) | [Link](https://arxiv.org/abs/2307.16789) | [Code](placeholder) | Large Language Models, Tool-use, APIs, Instruction Tuning, Generalization Ability |
| 2023.10 | GeoLLM: Extracting Geospatial Knowledge from Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.06213) | [Code](placeholder) | GeoLLM, Large Language Models, Geospatial Knowledge, Prediction Tasks, OpenStreetMap |
| 2023.11 | LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2311.05437) | [Code](placeholder) | LLaVA-Plus, multimodal assistant, skill repository, instruction-following data, tool use performance. |
| 2023.11 | AcademicGPT: Empowering Academic Research | ![image](placeholder) | [Link](https://arxiv.org/abs/2311.12315) | [Code](placeholder) | AcademicGPT, Large Language Models, academic research, domain-specific GPT, academic benchmarks. |
| 2023.12 | Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.06153) | [Code](placeholder) | Open Datasheets, Machine-readable Documentation, Open Datasets, Responsible AI, RAI Assessments |
| 2023.12 | Agent-based Learning of Materials Datasets from Scientific Literature | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.11690) | [Code](placeholder) | "Agent-based Learning", "Materials Datasets", "Scientific Literature", "Machine Learning", "Artificial Intelligence" |
| 2023.12 | GEAR-Up: Generative AI and External Knowledge-based Retrieval Upgrading Scholarly Article Searches for Systematic Reviews | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.09948) | [Code](placeholder) | Generative AI, External Knowledge-based Retrieval, Systematic Reviews, Query Expansion, Scholarly Article Searches |
| 2023.12 | ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (Local) Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.14607) | [Code](placeholder) | Generative AIs, Large Language Models, digital forensics, forensic report writing, automation. |
| 2024.01 | LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward | ![image](placeholder) | [Link](https://arxiv.org/abs/2401.03374) | [Code](placeholder) | Code Vulnerability, Reinforcement Learning, Semantic Reward, Large Language Model, Code Generation |
| 2024.01 | Weaver: Foundation Models for Creative Writing | ![image](placeholder) | [Link](https://arxiv.org/abs/2401.17268) | [Code](placeholder) | Weaver, Large Language Models, Creative Writing, Instruction Data Synthesis, Retrieval-Augmented Generation |
| 2024.02 | Prompt-Time Symbolic Knowledge Capture with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.00414) | [Code](placeholder) | Large Language Models, Prompt-driven Knowledge Capture, Knowledge Graphs, Prompt-to-Triple Generation, Synthetic Dataset. |
| 2024.02 | DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.17453) | [Code](placeholder) | Large Language Models, Automated Data Science, Case-Based Reasoning, Machine Learning Models, Kaggle Expert Knowledge |
| 2024.02 | An Autonomous Large Language Model Agent for Chemical Literature Data Mining | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.12993) | [Code](placeholder) | "Chemical synthesis", "Artificial intelligence", "Literature data mining", "Large language models", "Chemistry assistant" |
| 2024.02 | Multi-line AI-assisted Code Authoring | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.04141) | [Code](placeholder) | AI-assisted code authoring, multi-line suggestions, large language models, productivity, user experience. |
| 2024.02 | Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API | ![image](placeholder) | [Link](https://arxiv.org/abs/2402.18582) | [Code](placeholder) | Systematic Literature Reviews, AI-Enabled GPT-4 Assistant API, Article Selection, Academic Research, Bias Reduction |
| 2024.03 | AutoDev: Automated AI-Driven Development | ![image](placeholder) | [Link](https://arxiv.org/abs/2403.08299) | [Code](placeholder) | AI-driven development, software engineering, automated framework, AI Agents, secure environment. |
| 2024.03 | ChatDBG: An AI-Powered Debugging Assistant | ![image](placeholder) | [Link](https://arxiv.org/abs/2403.16354) | [Code](placeholder) | ChatDBG, AI-powered debugging, large language models, root cause analysis, collaborative dialogue. |
| 2024.03 | LLMs as Academic Reading Companions: Extending HCI Through Synthetic Personae | ![image](placeholder) | [Link](https://arxiv.org/abs/2403.19506) | [Code](placeholder) | Large Language Models, Academic Reading Companions, HCI, Synthetic Personae, Learning Enhancement |
| 2024.04 | DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.00439) | [Code](placeholder) | Natural Language Processing, PDF Documents, Document Question-Answering, Annotation Platform, Privacy-Preserving. |
| 2024.04 | Empowering Biomedical Discovery with AI Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.02831) | [Code](placeholder) | AI Scientists, Biomedical Research, Collaborative Agents, Large Datasets, Hypothesis Spaces |
| 2024.04 | ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.07738) | [Code](placeholder) | Large Language Models, ResearchAgent, Iterative Research, Scientific Literature, Idea Generation |
| 2024.04 | Exploring Human-AI Collaboration in Agile: Customised LLM Meeting Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.14871) | [Code](placeholder) | Agile software development, AI assistants, Daily Scrum, feature refinement, team collaboration dynamics. |
| 2024.05 | A System for Quantifying Data Science Workflows with Fine-Grained Procedural Logging and a Pilot Study | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.17845) | [Code](placeholder) | Data Science, Workflow, Procedural Logging, Jupyter Notebooks, AI-powered Code Tools |
| 2024.05 | A FAIR and Free Prompt-based Research Assistant | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.14601) | [Code](placeholder) | FAIR, Prompt-based, Research Assistant, Free, AI |
| 2024.05 | Automated Focused Feedback Generation for Scientific Writing Assistance | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.20477) | [Code](placeholder) | Automated Focused Feedback Generation, Scientific Writing, Large Language Models, Peer Reviews, Weaknesses in Scientific Papers |
| 2024.06 | BugBlitz-AI: An Intelligent QA Assistant | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.04356) | [Code](placeholder) | BugBlitz-AI, AI-powered validation toolkit, automated testing, result analysis, bug reporting. |
| 2024.04 | SARA: Smart AI Reading Assistant for Reading Comprehension | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.06906) | [Code](placeholder) | SARA, Eye Tracking, Reading Comprehension, Large Language Models, Mixed Reality Framework. |
| 2024.06 | The Use of AI-Robotic Systems for Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.17835) | [Code](placeholder) | AI-Robotic Systems, Scientific Discovery, Robot Scientist, Machine Learning, Systems Biology. |
| 2024.07 | Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.02651) | [Code](placeholder) | AI-Assisted Data Analysis, Interactive Task Decomposition, Steering, Verification, LLM-powered tools |
| 2024.07 | SeqMate: A Novel Large Language Model Pipeline for Automating RNA Sequencing | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.03381) | [Code](placeholder) | RNA sequencing, Large Language Model, Data preparation, Differential expression, Generative AI |
| 2024.07 | AI-Assisted SQL Authoring at Industry Scale | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.13280) | [Code](placeholder) | AI-Assisted SQL, generative AI, data analytics, SQL authoring, industry scale |
| 2024.08 | The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery | ![image](placeholder) | [Link](https://arxiv.org/abs/2408.06292) | [Code](placeholder) | Artificial General Intelligence, Scientific Discovery, Large Language Models, Machine Learning, Automated Review Process |
| 2024.08 | Genesis: Towards the Automation of Systems Biology Research | ![image](placeholder) | [Link](https://arxiv.org/abs/2408.10689) | [Code](placeholder) | AI, Systems Biology, Robot Scientists, Automation, Metabolic Models |
| 2024.09 | Collective Predictive Coding as Model of Science: Formalizing Scientific Activities Towards Generative Science | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.00102) | [Code](placeholder) | Collective Predictive Coding, Model of Science, Bayesian Inference, Scientific Activities, Generative Science |
| 2024.09 | SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.05556) | [Code](placeholder) | Artificial Intelligence, Multi-Agent Systems, Ontological Knowledge Graphs, Biologically Inspired Materials, Scientific Discovery Automation |
| 2024.09 | PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.00092) | [Code](placeholder) | PatentGPT, Large Language Model, Knowledge-based Fine-tuning, Patent Drafting, Intellectual Property Generation |
| 2024.09 | Steward: Natural Language Web Automation | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.15441) | [Code](placeholder) | Large Language Models, Web Automation, Natural Language, Browser Automation, Scalability |
| 2024.09 | NoTeeline: Supporting Real-Time, Personalized Notetaking with LLM-Enhanced Micronotes | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.16493) | [Code](placeholder) | NoTeeline, real-time notetaking, personalized notes, LLM-enhanced micronotes, AI-assisted tools. |
| 2024.10 | Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.09403) | [Code](placeholder) | "LLM-based multi-agent system", "scientific idea generation", "novelty", "teamwork", "autonomous scientific discovery" |
| 2024.10 | A Multi-LLM Orchestration Engine for Personalized, Context-Rich Assistance | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.10039) | [Code](placeholder) | Multi-LLM Orchestration Engine, Personalized Assistance, Context-Rich, Temporal Graph Database, Vector Database. |
| 2024.10 | Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.10136) | [Code](placeholder) | Real-Time Conversations, Retrieval Augmented Generation (RAG), Large Language Models (LLMs), Customer Contact Centers, Automated LLM-Agentic Workflow |
| 2024.10 | Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.11009) | [Code](placeholder) | AI-Assisted Writing, One-Shot Implicit Negative Feedback, Classifier Guidance, Text Generation, User Feedback Integration |
| 2024.10 | AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.17469) | [Code](placeholder) | AutoML, User-centered, GUI-based, Non-AI Experts, HCI Researchers |
| 2024.10 | Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.24119) | [Code](placeholder) | Large Language Models, Code Translation, Software Development, Scientific Computing, GenAI |
| 2024.10 | AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.21480) | [Code](placeholder) | Artificial Intelligence, Scientific Image Classification, Large Multimodal Models, Interpretability, Trust in AI |
| 2024.11 | Semantic Navigation for AI-assisted Ideation | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.03575) | [Code](placeholder) | AI-assisted Ideation, Semantic Navigation, LLM-supported, Data Input Filtering, Innovation Assistant Engagement. |
| 2024.11 | MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.08063) | [Code](placeholder) | Artificial Intelligence, Materials Science, Large Language Models, Human-Machine Collaboration, MatPilot |
| 2024.11 | AIGS: Generating Science from AI-Powered Automated Falsification | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.11910) | [Code](placeholder) | Artificial Intelligence, Automated Falsification, AI-Generated Science, Large Language Models, Scientific Discovery |
| 2024.11 | CycleResearcher: Improving Automated Research via Automated Review | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.00816) | [Code](placeholder) | Automated Research, Large Language Models (LLMs), Peer Review, Reinforcement Learning, Scientific Discovery |
| 2024.12 | A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.15404) | [Code](placeholder) | Retrieval-Augmented Generation, Data Science, Academic Literature Navigation, AI-Powered System, Context Relevance |
| 2024.12 | MetaScientist: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial Design | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.16270) | [Code](placeholder) | MetaScientist, Human-AI Synergistic Framework, Automated Mechanical Metamaterial Design, Hypothesis Generation, 3D Structure Synthesis |
| 2024.12 | Multi-Agent System for Cosmological Parameter Analysis | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.00431) | [Code](placeholder) | Multi-Agent System, Cosmological Parameter Analysis, Large Language Model, Monte Carlo Markov Chains, Scientific Workflows |
| 2024.12 | TapeAgents: a Holistic Framework for Agent Development and Optimization | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.08445) | [Code](placeholder) | TapeAgents, LLM Agent, Agent Development, Optimization, Tape-Centred Design |
| 2024.12 | LLMs can Realize Combinatorial Creativity: Generating Creative Ideas via LLMs for Scientific Research | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.14141) | [Code](placeholder) | Large Language Models, Combinatorial Creativity, Scientific Research, Idea Generation, Cross-Domain Knowledge Discovery. |
| 2024.12 | EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.18100) | [Code](placeholder) | EvoPat, Multi-LLM, Patent Summarization, Analysis Agent, Retrieval-Augmented Generation (RAG) |
| 2024.12 | VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.18161) | [Code](placeholder) | AI Assistant, Natural Human-Instrument Interaction, Scientific User Facilities, Modular Architecture, Large Language Models (LLMs) |
| 2024.12 | Automated Code Review In Practice | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.18531) | [Code](placeholder) | Automated Code Review, Large Language Models (LLMs), Software Quality, Pull Request, AI-assisted Tools |
| 2025.01 | Agent Laboratory: Using LLM Agents as Research Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.04227) | [Code](placeholder) | Agent Laboratory, LLM-based framework, scientific discovery, research process, autonomous research methods |
| 2025.01 | Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.03916) | [Code](placeholder) | Artificial Intelligence, Auto-research, Closed-loop, Open-ended, Scientific Research Paradigm |
| 2025.01 | Knowledge Retrieval Based on Generative AI | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.04635) | [Code](placeholder) | Knowledge Retrieval, Generative AI, Retrieval-Augmented Generation (RAG), Large Language Model (LLM), Data Privacy |
| 2025.01 | Automating Care by Self-maintainability for Full Laboratory Automation | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.05789) | [Code](placeholder) | Full Laboratory Automation, Self-maintainability, Experimental Workflows, Resource Management, Adaptive Responses |
| 2025.02 | AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.05957) | [Code](placeholder) | AutoAgent, Fully-Automated, Zero-Code, LLM Agents, Natural Language Alone |
| 2025.02 | AIDE: AI-Driven Exploration in the Space of Code | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.13138) | [Code](placeholder) | Machine Learning, Artificial Intelligence, Code Optimization, Large Language Models, Trial-and-Error Tasks |
| 2025.02 | Towards an AI co-scientist | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.18864) | [Code](placeholder) | AI co-scientist, hypothesis generation, biomedical discovery, drug repurposing, novel target discovery |
| 2025.02 | ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.00989) | [Code](placeholder) | ChartCitor, Multi-Agent Framework, Fine-Grained Chart Visual Attribution, Large Language Models, Chart Question-Answering Tasks |
| 2025.02 | Knowledge Synthesis of Photosynthesis Research Using a Large Language Model | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.01059) | [Code](placeholder) | "Large Language Models", "Photosynthesis Research", "Knowledge Synthesis", "Retrieval-Augmented Generation", "Prompt Optimization" |
| 2025.02 | Accelerating Scientific Research Through a Multi-LLM Framework | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.07960) | [Code](placeholder) | Large Language Models (LLMs), Multi-LLM framework, Artificial Research Innovator Assistant (ARIA), Research process, Cross-disciplinary tasks. |
| 2025.02 | Automated Capability Discovery via Model Self-Exploration | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.07577) | [Code](placeholder) | Automated Capability Discovery, Foundation Models, Open-endedness, Evaluation, AI Systems. |
| 2025.02 | CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.10884) | [Code](placeholder) | AI coding assistants, accessible web development, accessibility violations, GitHub Copilot, CodeA11y extension. |
| 2025.02 | From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.15237) | [Code](placeholder) | Knowledge Graph, Retrieval-Augmented Generation, Large Language Models, AI Assistant, Response Relevance. |
| 2025.02 | AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect Graphical Interface Commands as General-Purpose Tools | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.18736) | [Code](placeholder) | AI-Instruments, Direct Manipulation, Ambiguous Intents, Creative AI-Assisted Design, Graphical Interface Commands. |
| 2025.03 | Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.01508) | [Code](placeholder) | Artificial General Intelligence (AGI), novelty assessment, Relative Neighbor Density (RND), domain-agnostic algorithm, scientific discovery. |

### Rethinking
| Date | Paper | Figure | Link | Code | Keywords |
| :--- | :---- | :----- | :--- | :--- | :------- |
| 2021.01 | How Much Automation Does a Data Scientist Want? | ![image](placeholder) | [Link](https://arxiv.org/abs/2101.03970) | [Code](placeholder) | Data Science, Machine Learning, Automation, User-Centered, AutoML Framework |
| 2021.03 | Toward Building Science Discovery Machines | ![image](placeholder) | [Link](https://arxiv.org/abs/2103.15551) | [Code](placeholder) | Scientific Discovery, Machine Learning, AI Systems, Problem-Solving, Principles of Science Discovery |
| 2021.11 | Automated scholarly paper review: Concepts, technologies, and challenges | ![image](placeholder) | [Link](https://arxiv.org/abs/2111.07533) | [Code](placeholder) | Automated scholarly paper review, Artificial intelligence, Peer review, Research evaluation, Academic publishing |
| 2023.01 | How Data Scientists Review the Scholarly Literature | ![image](placeholder) | [Link](https://arxiv.org/abs/2301.03774) | [Code](placeholder) | Data Scientists, Scholarly Literature, Literature Review Practices, Information Overload, Interdisciplinary Field |
| 2023.03 | Practices and Challenges of Using GitHub Copilot: An Empirical Study | ![image](placeholder) | [Link](https://arxiv.org/abs/2303.08733) | [Code](placeholder) | GitHub Copilot, AI Pair Programmer, programming languages, IDEs, challenges |
| 2023.03 | A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges | ![image](placeholder) | [Link](https://arxiv.org/abs/2303.17125) | [Code](placeholder) | AI Programming Assistants, Usability, Developers, Software Engineering, Cognitive Effort |
| 2023.05 | Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems | ![image](placeholder) | [Link](https://arxiv.org/abs/2305.02251) | [Code](placeholder) | Automated Scientific Discovery, Equation Discovery, Autonomous Discovery Systems, Deep Neural Networks, Nobel Turing Grand Challenge |
| 2023.05 | Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond | ![image](placeholder) | [Link](https://arxiv.org/abs/2305.15299) | [Code](placeholder) | Artificial Intelligence, Research Ethics, ChatGPT, Generative AI, Scientific Integrity |
| 2023.06 | The Future of AI-Assisted Writing | ![image](placeholder) | [Link](https://arxiv.org/abs/2306.16641) | [Code](placeholder) | Artificial Intelligence, Natural Language Generation, AI-Assisted Writing, Information Retrieval, User Study |
| 2023.07 | What Should Data Science Education Do with Large Language Models? | ![image](placeholder) | [Link](https://arxiv.org/abs/2307.02792) | [Code](placeholder) | Large Language Models, Data Science Education, ChatGPT, AI-guided Programming, Pedagogy Evolution |
| 2023.07 | The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence | ![image](placeholder) | [Link](https://arxiv.org/abs/2307.07522) | [Code](placeholder) | Artificial Intelligence, Generative AI, Large Language Models, Scientific Discovery, Fundamental Science |
| 2023.07 | AI empowering research: 10 ways how science can benefit from AI | ![image](placeholder) | [Link](https://arxiv.org/abs/2307.10265) | [Code](placeholder) | Artificial Intelligence, Scientific Research, Data Analysis, Human-AI Collaboration, Creativity in Science |
| 2023.10 | AI for Mathematics: A Cognitive Science Perspective | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.13021) | [Code](placeholder) | Artificial Intelligence, Mathematics, Cognitive Science, Large Language Models, Mathematical Systems |
| 2023.10 | Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities | ![image](placeholder) | [Link](https://arxiv.org/abs/2310.16164) | [Code](placeholder) | Large Language Models, data science, conversational challenges, design recommendations, AI-powered chatbots |
| 2023.11 | Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance | ![image](placeholder) | [Link](https://arxiv.org/abs/2311.03311) | [Code](placeholder) | Large Language Models, Gender Bias, AI Writing Support, Educational Writing, Bias Transfer |
| 2023.12 | Drivers and Barriers of AI Adoption and Use in Scientific Research | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.09843) | [Code](placeholder) | Artificial Intelligence, Adoption, Scientific Research, Human Capital, Barriers and Drivers |
| 2023.12 | Generative AI in Writing Research Papers: A New Type of Algorithmic Bias and Uncertainty in Scholarly Work | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.10057) | [Code](placeholder) | Generative AI, Algorithmic Bias, Uncertainty, Scholarly Work, Research Manuscripts |
| 2023.12 | Exploring the intersection of Generative AI and Software Development | ![image](placeholder) | [Link](https://arxiv.org/abs/2312.14262) | [Code](placeholder) | Generative AI, Software Engineering, Zero-shot prompting, Multimodal chain-of-thought, Vector embeddings |
| 2024.01 | Can AI Assistants Know What They Don't Know? | ![image](placeholder) | [Link](https://arxiv.org/abs/2401.13275) | [Code](placeholder) | AI Assistants, Large Language Models (LLMs), Open-domain Question Answering, Factual Errors, "I don't know" (Idk) dataset |
| 2024.03 | "It is there, and you need it, so why do you not use it?" Achieving better adoption of AI systems by domain experts, in the case study of natural science research | ![image](placeholder) | [Link](https://arxiv.org/abs/2403.16895) | [Code](placeholder) | Artificial Intelligence, adoption, domain experts, natural science research, human-AI collaboration |
| 2024.03 | Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals | ![image](placeholder) | [Link](https://arxiv.org/abs/2403.14592) | [Code](placeholder) | AI coding assistants, in-IDE, AI for Software Engineering, backend designs, app data collection |
| 2024.04 | Deceptive Patterns of Intelligent and Interactive Writing Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.09375) | [Code](placeholder) | Large Language Models, Intelligent Writing Assistants, Deceptive Design Patterns, Chatbot-like UI, Interaction Design Impact |
| 2024.04 | How far are AI-powered programming assistants from meeting developers' needs? | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.12000) | [Code](placeholder) | AI-powered programming assistants, software development tasks, code quality, productivity, user experience |
| 2024.04 | Augmenting the Author: Exploring the Potential of AI Collaboration in Academic Writing | ![image](placeholder) | [Link](https://arxiv.org/abs/2404.16071) | [Code](placeholder) | Generative AI, Academic Writing, Prompt Design, Human-Computer Interaction, AI Collaboration |
| 2024.05 | From Complexity to Clarity: How AI Enhances Perceptions of Scientists and the Public's Understanding of Science | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.00706) | [Code](placeholder) | AI, science communication, public understanding, linguistic simplicity, scientific dissemination |
| 2024.05 | Transforming Software Development with Generative AI: Empirical Insights on Collaboration and Workflow | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.01543) | [Code](placeholder) | Generative AI, software development, collaboration, workflow, ChatGPT |
| 2024.05 | What Can Natural Language Processing Do for Peer Review? | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.06563) | [Code](placeholder) | Natural Language Processing, Peer Review, Scientific Articles, Quality Control, Large Language Models |
| 2024.05 | Using ChatGPT for Thematic Analysis | ![image](placeholder) | [Link](https://arxiv.org/abs/2405.08828) | [Code](placeholder) | AI-driven tools, qualitative thematic analysis, GPT model, research efficiency, ethical concerns |
| 2024.06 | Using AI-Based Coding Assistants in Practice: State of Affairs, Perceptions, and Ways Forward | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.07765) | [Code](placeholder) | AI assistants, software development, usage patterns, developer perceptions, future improvements |
| 2024.06 | Explain the Black Box for the Sake of Science: the Scientific Method in the Era of Generative Artificial Intelligence | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.10557) | [Code](placeholder) | Scientific Method, Generative Artificial Intelligence, Explainable AI, Scientific Discovery, Interpretability-guided Explanations (IGEs) |
| 2024.06 | Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models? | ![image](placeholder) | [Link](https://arxiv.org/abs/2406.11375) | [Code](placeholder) | Analogy, Teacher Models, Student Models, Scientific Concepts Understanding, Analogical Reasoning |
| 2024.07 | Large Language Models as Misleading Assistants in Conversation | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.11789) | [Code](placeholder) | Large Language Models, Misleading Assistants, Conversation, Deception, Reading Comprehension Task |
| 2024.07 | The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.12015) | [Code](placeholder) | Generative AI, peer reviewers, research writing, AI-augmented manuscripts, impartial evaluations |
| 2024.07 | Exploring the Evidence-Based Beliefs and Behaviors of LLM-Based Programming Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2407.13900) | [Code](placeholder) | Artificial Intelligence, Large Language Models, Software Engineering, Evidence-Based Practices, Programming Assistants |
| 2024.08 | Generative AI Tools in Academic Research: Applications and Implications for Qualitative and Quantitative Research Methodologies | ![image](placeholder) | [Link](https://arxiv.org/abs/2408.06872) | [Code](placeholder) | Generative Artificial Intelligence, academic research, qualitative research, quantitative research, ethical implications |
| 2024.09 | Emerging Reliance Behaviors in Human-AI Text Generation: Hallucinations, Data Quality Assessment, and Cognitive Forcing Functions | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.08937) | [Code](placeholder) | Human-AI collaborative text generation, hallucinations, cognitive forcing functions, data quality assessment, Large Language Models (LLMs) |
| 2024.09 | Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.11192) | [Code](placeholder) | Long-Term Memory, Personal AI Assistants, Ethical Considerations, Large Language Models, Deployment Implications |
| 2024.09 | Mining Causality: AI-Assisted Search for Instrumental Variables | ![image](placeholder) | [Link](https://arxiv.org/abs/2409.14202) | [Code](placeholder) | Instrumental Variables, Causal Inference, Large Language Models, Counterfactual Reasoning, Regression Discontinuity Design |
| 2024.10 | The why, what, and how of AI-based coding in scientific research | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.02156) | [Code](placeholder) | AI-based coding, scientific research, large language models, coding assistance, workflow strategies |
| 2024.10 | How Does the Disclosure of AI Assistance Affect the Perceptions of Writing? | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.04545) | [Code](placeholder) | AI assistance, writing perceptions, disclosure, quality evaluations, human-AI co-creation |
| 2024.10 | Need Help? Designing Proactive AI Assistants for Programming | ![image](placeholder) | [Link](https://arxiv.org/abs/2410.04596) | [Code](placeholder) | Proactive AI Assistants, Programming, Large Language Models, Mixed-Initiative Interaction, User Experience |
| 2024.11 | Disrupting Test Development with AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.02328) | [Code](placeholder) | AI Assistants, Test Development, Software Development, Test Pyramid, Automated Testing |
| 2024.11 | AI-Empowered Human Research Integrating Brain Science and Social Sciences Insights | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.12761) | [Code](placeholder) | Artificial Intelligence, Human Research, Brain Science, Social Sciences, Human-AI Joint Research |
| 2024.11 | Probing the limitations of multimodal language models for chemistry and materials research | ![image](placeholder) | [Link](https://arxiv.org/abs/2411.16955) | [Code](placeholder) | Artificial Intelligence, Multimodal Language Models, Chemistry, Materials Science, Benchmark Evaluation |
| 2024.12 | The impact of AI on engineering design procedures for dynamical systems | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.12230) | [Code](placeholder) | Artificial Intelligence, Engineering Design, Dynamical Systems, Mechatronic Systems, V-model Design Process |
| 2024.12 | Hints Help Finding and Fixing Bugs Differently in Python and Text-based Program Representations | ![image](placeholder) | [Link](https://arxiv.org/abs/2412.12471) | [Code](placeholder) | AI programming assistants, bug fixing, hints, program representations, user understanding |
| 2025.01 | Experience with GitHub Copilot for Developer Productivity at Zoominfo | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.13282) | [Code](placeholder) | GitHub Copilot, Developer Productivity, Zoominfo, AI-assisted software development, Enterprise deployment |
| 2025.01 | Towards Decoding Developer Cognition in the Age of AI Assistants | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.02684) | [Code](placeholder) | AI assistants, developer productivity, cognitive load, programming tools, expertise levels |
| 2025.01 | "It makes you think": Provocations Help Restore Critical Thinking to AI-Assisted Knowledge Work | ![image](placeholder) | [Link](https://arxiv.org/abs/2501.17247) | [Code](placeholder) | Generative AI, Critical Thinking, Knowledge Work, Provocations, Metacognitive Thinking |
| 2025.02 | Evaluating Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial Research Intelligence' (ARI)? | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.14297) | [Code](placeholder) | Artificial Research Intelligence (ARI), AI Scientist, autonomous research, Sakana, research automation |
| 2025.02 | Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path? | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.15657) | [Code](placeholder) | AI safety, generalist AI agents, Scientist AI, non-agentic AI, precautionary principle |
| 2025.02 | Performance Evaluation of Large Language Models in Statistical Programming | ![image](placeholder) | [Link](https://arxiv.org/abs/2502.13117) | [Code](placeholder) | Large Language Models, Statistical Programming, SAS Programming, Performance Evaluation, Automatic Code Generation |
| 2025.03 | Position: AI agents should be regulated based on autonomous action sequences | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.04750) | [Code](placeholder) | AI agents, regulation, autonomous action sequences, existential risks, inference-time computation |
| 2025.03 | Unlocking the Potential of AI Researchers in Scientific Discovery: What Is Missing? | ![image](placeholder) | [Link](https://arxiv.org/abs/2503.05822) | [Code](placeholder) | AI researchers, scientific discovery, AI4Science, Diffusion of Innovation, integration of AI expertise |

### Cooperation Enhencing Research#ÈÄöËøáÊàë‰ª¨‰ª•ÂâçÁöÑÂ∑•‰Ωú„ÄÅ‰ΩìÈ™åÂºèÂÖ±ÂêåÂ≠¶‰π†ÊàñÂæÆË∞ÉÊ®°ÂûãÂèÇÊï∞Á≠âÊñπÊ≥ïÊèêÈ´ò‰ª£ÁêÜÂú®Â§ö‰ª£ÁêÜÁ≥ªÁªüÂÜÖÁöÑÂêà‰ΩúËÉΩÂäõ„ÄÇ













